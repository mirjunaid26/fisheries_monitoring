<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fisheries Monitoring Challenge</title>
    <link rel="stylesheet" href="styles.css">
    <!-- No external fonts needed, using system fonts for speed and clean look -->
</head>

<body>

    <!-- Hero Header -->
    <header class="container">
        <h1>Fisheries Monitoring Challenge</h1>
        <div class="subtitle">Deep Learning for Sustainable Fishing Practices</div>
        <div class="authors">
            <strong>Junaid Mir</strong> &bull; Kaggle Competition Report &bull; December 2025
        </div>
        <div class="header-links">
            <a href="https://github.com/mirjunaid26/fisheries_monitoring" target="_blank">[GitHub Repository]</a>
            <a href="report.md" target="_blank">[Download Paper]</a>
            <a href="#dataset">[View Dataset]</a>
        </div>
    </header>

    <!-- Sticky Navigation -->
    <nav>
        <div class="nav-container">
            <a href="#abstract" class="nav-link">Abstract</a>
            <a href="#dataset" class="nav-link">Dataset</a>
            <a href="#methods" class="nav-link">Methods</a>
            <a href="#results" class="nav-link">Results</a>
            <a href="#demo" class="nav-link">Demo</a>
            <a href="#team" class="nav-link">Team</a>
        </div>
    </nav>

    <div class="container">

        <!-- Abstract -->
        <section id="abstract">
            <p class="abstract">
                <strong>Abstract.</strong> Overfishing and Illegal, Unreported, and Unregulated (IUU) fishing threaten
                global marine ecosystems. To scale monitoring efforts beyond human observers, we present an automated
                Electronic Monitoring (EM) solution driven by Deep Learning. Our system addresses critical challenges in
                marine computer visionâ€”specifically <strong>low-light degradation</strong>, <strong>extreme class
                    imbalance</strong>, and <strong>resource-constrained edge deployment</strong>. By integrating a
                <strong>ConvNeXt V2</strong> backbone, <strong>Zero-DCE++</strong> for low-light enhancement, and
                <strong>LDAM Loss</strong> for long-tailed recognition, we achieve robust species classification
                suitable for real-time deployment on NVIDIA Jetson edge devices.
            </p>
        </section>

        <!-- Dataset -->
        <section id="dataset">
            <h2>Dataset & Challenges</h2>
            <p>
                The dataset comprises imagery from commercial fishing vessels, featuring 8 distinct classes including
                Albacore (ALB), Bigeye Tuna (BET), and Sharks. The data reflects the chaotic nature of wild
                environments:
            </p>
            <ul>
                <li><strong>Class Imbalance</strong>: Follows Zipf's law, with rare protected species (Sharks) vastly
                    outnumbered by target Tuna species.</li>
                <li><strong>Environmental Noise</strong>: Includes harsh glare, water droplets, and pitch-black night
                    footage.</li>
                <li><strong>Occlusion</strong>: Fish are frequently overlapped or obscured by gear.</li>
            </ul>

            <h3>Sample Images</h3>
            <div id="gallery-grid" class="gallery-grid">
                <!-- Injected via script.js from public/predictions.json -->
            </div>
        </section>

        <!-- Methods -->
        <section id="methods">
            <h2>Methodology</h2>
            <h3>1. Backbone: ConvNeXt V2</h3>
            <p>
                We transitioned from a standard ResNet50 to <strong>ConvNeXt V2</strong>. This architecture modernizes
                CNNs with Transformer-like design choices (large 7x7 kernels, GeLU activations) and introduces
                <strong>Global Response Normalization (GRN)</strong>. GRN prevents feature collapse, crucially improving
                performance on fine-grained discrimination between morphologically similar tuna species.
            </p>

            <h3>2. Low-Light Enhancement</h3>
            <p>
                To handle night operations, we integrated <strong>Zero-DCE++ (Zero-Reference Deep Curve
                    Estimation)</strong>. Unlike GANs, Zero-DCE estimates light-enhancement curves to iteratively adjust
                pixel dynamic range. It runs at >1000 FPS, normalizing day and night footage to a common domain before
                classification.
            </p>

            <h3>3. Long-Tailed Learning</h3>
            <p>
                To protect rare species, we replaced standard Cross-Entropy loss with <strong>LDAM
                    (Label-Distribution-Aware Margin) Loss</strong> combined with <strong>Deferred Re-Weighting
                    (DRW)</strong>. This enforces larger decision margins for minority classes, significantly boosting
                recall for endangered species.
            </p>
        </section>

        <!-- Results -->
        <section id="results">
            <h2>Results</h2>
            <p>
                The proposed holistic pipeline delivers superior robustness compared to baseline methods. The
                integration of Zero-DCE++ extended effective monitoring hours to 24/7.
            </p>

            <table class="results-table">
                <thead>
                    <tr>
                        <th>Architecture</th>
                        <th>Task</th>
                        <th>Performance</th>
                        <th>Key Advantage</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>ResNet-50</td>
                        <td>Classification</td>
                        <td>~61% (Family Level)</td>
                        <td>Standard Baseline</td>
                    </tr>
                    <tr>
                        <td><strong>ConvNeXt V2</strong></td>
                        <td>Classification</td>
                        <td><strong>85.5% (ImageNet)</strong></td>
                        <td>Robust to Pose & Scale</td>
                    </tr>
                    <tr>
                        <td>YOLOv8</td>
                        <td>Detection</td>
                        <td>71% mAP</td>
                        <td>High Speed Edge Inference</td>
                    </tr>
                    <tr>
                        <td>LDAM Strategy</td>
                        <td>Long-Tail</td>
                        <td>+15% Top-1</td>
                        <td>Improved Rare Class Recall</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- Demo -->
        <section id="demo">
            <h2>Interactive Demo & Edge Deployment</h2>
            <p>
                The system is designed for the <strong>NVIDIA Jetson Orin Nano</strong>, utilizing TensorRT optimization
                to run the full pipeline (Enhancement &rarr; Detection &rarr; Classification) in real-time (15+ FPS) at
                the edge. An <strong>Active Learning</strong> loop buffers high-uncertainty frames (using Entropy
                sampling) for human review.
            </p>

            <div class="demo-container" id="drop-zone">
                <div class="demo-icon">&#8681;</div>
                <div class="demo-text">
                    Drag & drop an image here to simulate Edge Inference
                </div>
                <input type="file" id="file-input" hidden accept="image/*">
            </div>

            <div id="demo-result" class="demo-result">
                <img id="result-img" class="result-img-preview" src="" alt="Uploaded">
                <div class="result-bars" id="result-bars">
                    <!-- Bars injected by JS -->
                </div>
            </div>
        </section>

        <!-- Team -->
        <section id="team">
            <h2>Team</h2>
            <p>
                <strong>Junaid Mir</strong><br>
                Project Lead & Main Developer<br>
                <em>Implemented training pipeline, data augmentations, and web visualization.</em>
            </p>
        </section>

        <footer>
            &copy; 2025 Fisheries Monitoring Project. Images courtesy of The Nature Conservancy. <br>
            Designed with &hearts; in the style of CS231n.
        </footer>

    </div>

    <script src="script.js"></script>
</body>

</html>