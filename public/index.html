<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fisheries Monitoring | Model Results</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&family=Outfit:wght@500;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div class="container">
        <header>
            <h1>Fisheries Monitoring</h1>
            <p class="subtitle">Showcasing the performance of our deep learning model in classifying fish species for
                The Nature Conservancy.</p>
            <a href="https://github.com/mirjunaid26/fisheries_monitoring" class="btn">View on GitHub</a>
        </header>

        <main class="grid">
            <div class="card" data-modal="accuracy-modal">
                <h2>Accuracy</h2>
                <div class="stat-value">95.5%</div>
                <p>Validation accuracy achieved on Fold 0 after 10 epochs using ResNet50.</p>
            </div>

            <div class="card" data-modal="model-modal">
                <h2>Model Architecture</h2>
                <div class="stat-value">ResNet50</div>
                <p>Pretrained on ImageNet, fine-tuned for fisheries monitoring using Transfer Learning.</p>
            </div>

            <div class="card" data-modal="dataset-modal">
                <h2>Dataset</h2>
                <div class="stat-value">8 Classes</div>
                <p>Classifying ALB, BET, DOL, LAG, NoF, OTHER, SHARK, and YFT.</p>
            </div>
        </main>

        <section class="gallery-section">
            <h2 class="gallery-title">Classification Showcase</h2>
            <div id="gallery" class="gallery-grid">
                <!-- Gallery items will be injected here by script.js -->
            </div>
        </section>

        <div class="card">
            <h2>Project Overview</h2>
            <p>This project leverages Computer Vision and Deep Learning to assist in fisheries monitoring. By
                automatically detecting and classifying fish species from boat camera footage, we aim to support
                sustainable fishing practices.</p>
            <br>
            <h3>Technical Stack</h3>
            <div style="margin-top: 1rem;">
                <span class="tech-tag">PyTorch</span>
                <span class="tech-tag">Albumentations</span>
                <span class="tech-tag">ResNet50</span>
                <span class="tech-tag">Transfer Learning</span>
                <span class="tech-tag">OpenCV</span>
            </div>
            <br>
            <p>The solution utilizes a robust PyTorch pipeline. It employs <strong>Albumentations</strong> for advanced
                data augmentation (Horizontal Flips, Random Brightness/Contrast) to handle lighting variations common in
                maritime environments. The training process uses Stratified K-Fold validation to ensure reliable
                performance metrics across different data splits.</p>
        </div>

        <footer class="footer">
            <p>&copy; 2025 Fisheries Monitoring Project.</p>
        </footer>
    </div>

    <!-- Modals -->
    <div class="modal-overlay" id="accuracy-modal">
        <div class="modal-content">
            <button class="modal-close">&times;</button>
            <div class="modal-body">
                <h3>Accuracy Metrics</h3>
                <p>The model achieved a <strong>95.5% Validation Accuracy</strong> on Fold 0.</p>
                <ul>
                    <li><strong>Loss Function:</strong> CrossEntropyLoss</li>
                    <li><strong>Optimizer:</strong> Adam (Learning Rate: 1e-4)</li>
                    <li><strong>Scheduler:</strong> ReduceLROnPlateau (Factor: 0.5, Patience: 3)</li>
                </ul>
                <p>This high accuracy demonstrates the model's ability to generalize well to unseen images of fish on
                    boat decks.</p>
            </div>
        </div>
    </div>

    <div class="modal-overlay" id="model-modal">
        <div class="modal-content">
            <button class="modal-close">&times;</button>
            <div class="modal-body">
                <h3>Model Architecture</h3>
                <p>We utilize a <strong>ResNet50</strong> backbone, a 50-layer deep Convolutional Neural Network (CNN)
                    known for its residual learning framework.</p>
                <ul>
                    <li><strong>Pretraining:</strong> ImageNet weights were used to initialize the model, accelerating
                        convergence.</li>
                    <li><strong>Modifications:</strong> The final Fully Connected (FC) layer was replaced to output 8
                        classes instead of 1000.</li>
                    <li><strong>Training Strategy:</strong> Transfer Learning with fine-tuning.</li>
                </ul>
            </div>
        </div>
    </div>

    <div class="modal-overlay" id="dataset-modal">
        <div class="modal-content">
            <button class="modal-close">&times;</button>
            <div class="modal-body">
                <h3>Dataset Details</h3>
                <p>The dataset consists of images captured from fishing boats. The goal is to identify the fish species
                    to monitor catch.</p>
                <h4>Target Classes (8):</h4>
                <ul>
                    <li><strong>ALB:</strong> Albacore Tuna</li>
                    <li><strong>BET:</strong> Bigeye Tuna</li>
                    <li><strong>DOL:</strong> Dolphinfish (Mahi-Mahi)</li>
                    <li><strong>LAG:</strong> Opah (Moonfish)</li>
                    <li><strong>NoF:</strong> No Fish (Empty deck)</li>
                    <li><strong>OTHER:</strong> Other species</li>
                    <li><strong>SHARK:</strong> Sharks</li>
                    <li><strong>YFT:</strong> Yellowfin Tuna</li>
                </ul>
                <h4>Preprocessing:</h4>
                <p>Images are resized to <strong>224x224</strong> and normalized using ImageNet mean/std stats.</p>
            </div>
        </div>
    </div>

    <script src="script.js"></script>
</body>

</html>